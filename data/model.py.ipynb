{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1*X GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=(1024*4))])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_az_dataset(datasetpath):\n",
    "    \n",
    "    labels = []\n",
    "    data = []\n",
    "    \n",
    "    for row in open(datasetpath):\n",
    "        row = row.split(\",\")\n",
    "        label = int(row[0])\n",
    "        image = np.array([int(x) for x in row[1:]],dtype = \"uint8\")\n",
    "        \n",
    "        #reshaping the image in 28*28 matrix\n",
    "        \n",
    "        image = image.reshape((28,28))\n",
    "        \n",
    "        #updating data and lables\n",
    "        \n",
    "        data.append(image)\n",
    "        labels.append(label)\n",
    "        \n",
    "    data = np.array(data,dtype=\"float32\")\n",
    "    labels = np.array(labels,dtype=\"int\")\n",
    "    \n",
    "    return (data,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_dataset():\n",
    "    \n",
    "    ((train_data,train_labels),(test_data,test_labels)) = mnist.load_data()\n",
    "    \n",
    "    data = np.vstack([train_data,test_data])\n",
    "    labels = np.hstack([test_labels,train_labels])\n",
    "    \n",
    "    return (data,labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a_z ,label_a_z = load_az_dataset(\"../data/archive/a.csv\")\n",
    "data_mnist, label_mnist = load_mnist_dataset()\n",
    "label_a_z += 10\n",
    "    \n",
    "data_total = np.vstack([data_mnist,data_a_z])\n",
    "labels_total = np.hstack([label_mnist,label_a_z])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442451,)\n",
      "(442451, 28, 28)\n",
      "(372451,)\n"
     ]
    }
   ],
   "source": [
    "print(labels_total.shape)\n",
    "print(data_total.shape)\n",
    "print(label_a_z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442451, 28, 28)\n",
      "(353960, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "data_dim = np.expand_dims(data_total, axis=-1)\n",
    "print(data_total.shape)\n",
    "# data_total /= 255.0\n",
    "data_dim = np.divide(data_dim,255.0)\n",
    "(X_train ,X_test, y_train , y_test) = train_test_split(data_dim,labels_total, test_size=0.20, stratify=labels_total, random_state=42)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353960,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "LR = 1e-1\n",
    "BS = 128\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "le = LabelBinarizer()\n",
    "labels = le.fit_transform(labels_total)\n",
    "counts = labels.sum(axis=0)\n",
    "\n",
    "classTotals = labels.sum(axis=0)\n",
    "classWeight = {}\n",
    "for i in range(0, len(classTotals)):\n",
    "    classWeight[i] = classTotals.max() / classTotals[i]\n",
    "print(len(classWeight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_t = tf.keras.Input(shape = (32,32,1))\n",
    "res_model =tf.keras.applications.ResNet50(include_top=False, weights=\"imagenet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D,Conv2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(3,(3, 3),padding = \"same\",input_shape=(32,32,1)))\n",
    "model.add(res_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(len(le.classes_),kernel_regularizer=tf.keras.regularizers.l2(0.0001),activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 3)         30        \n",
      "_________________________________________________________________\n",
      "resnet50 (Model)             multiple                  23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 36)                73764     \n",
      "=================================================================\n",
      "Total params: 23,661,506\n",
      "Trainable params: 23,608,386\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.SGD(LR,decay = LR/EPOCHS) \n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353960,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(datagen.flow(X_train,y_train,batch_size = BS),\n",
    "                   validation_data = (X_test,y_test),\n",
    "                   steps_per_epoch = len(X_train)/BS,\n",
    "                   epochs = EPOCHS,\n",
    "                  class_weight = classWeight,\n",
    "                   verbose = 1)\n",
    "\n",
    "labelNames = \"0123456789\"\n",
    "labelNames += \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "labelNames = [l for l in labelNames]\n",
    "\n",
    "#model evaluation\n",
    "\n",
    "pred = model.predict(y_test,batch_size = BS)\n",
    "print(classification_report(y_test.argmax(axis=1)),\n",
    "                             pred.argmax(axis=1),\n",
    "                             target_names = labelNames)\n",
    "\n",
    "model.save(\"resNet50.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
